{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3MCQ7rW6ejN",
        "outputId": "a5f5207d-8529-47c9-d80b-8a056afd7e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.23.0-py3-none-any.whl (36 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.13)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 replicate-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0nWDKSDCwRm",
        "outputId": "a0a954b4-d4c0-401a-a148-74bfbb58600d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.2-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.14-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.14 (from langchain)\n",
            "  Downloading langchain_core-0.1.14-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.0.84,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.2 langchain-community-0.0.14 langchain-core-0.1.14 langsmith-0.0.83 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['REPLICATE_API_KEY'] = \"r8_Hd3shNaVKrK9SjYwL3PY47EUNGgMkSF3XuFcT\""
      ],
      "metadata": {
        "id": "IyIZd2_G6oR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export REPLICATE_API_TOKEN=r8_Hd3shNaVKrK9SjYwL3PY47EUNGgMkSF3XuFcT"
      ],
      "metadata": {
        "id": "eLfS5JUp78z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "model = replicate.Client(api_token=os.environ['REPLICATE_API_KEY'])\n",
        "p = \"\"\"summarize in detail about this content (within 25 words): Lorem ipsum is derived from the Latin phrase \"dolorem ipsum\", which roughly translates to \"pain itself\". It's been the industry standard dummy text since the 1500s, when an unknown printer scrambled a galley of type to make a type specimen book.\n",
        "Lorem ipsum helps designers plan out where content will sit without needing to wait for the content to be written and approved. It features scrambled Latin text, which emphasizes the design over content of the layout.\n",
        "You can use a Lorem ipsum generator to create Lorem ipsum text. You can also add Lorem ipsum to a Microsoft Word document by putting in a number representing how many paragraphs you would like, and then how many sentences per paragraph.\"\"\"\n",
        "output = model.run(\n",
        "    \"joehoover/falcon-40b-instruct:7eb0f4b1ff770ab4f68c3a309dd4984469749b7323a3d47fd2d5e09d58836d3c\",\n",
        "    input={\n",
        "        \"seed\": -1,\n",
        "        \"top_p\": 1,\n",
        "        \"prompt\": p,\n",
        "        \"max_length\": 500,\n",
        "        \"temperature\": 0.7,\n",
        "        \"length_penalty\": 1,\n",
        "        \"repetition_penalty\": 1\n",
        "    }\n",
        ")\n",
        "for val in output:\n",
        "  print(val, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPtX6Hpn7Fo1",
        "outputId": "f3da4a73-f2b0-4258-ab73-fb4ab1070a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For example, \"=lorem(3,3)\" will generate three paragraphs with three sentences each. This can help you visualize the layout of your design. \n",
            "In summary, Lorem ipsum is a filler text used in design to help visualize the layout and design of a document without needing content."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# magics to auto-reload external modules in case you are making changes to langchain while working on this notebook\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "l-S8XoXe7ObF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get a token: https://replicate.com/account\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbv9XqZHCTRO",
        "outputId": "87dd5a86-dd95-4208-c38b-04a3d4501c82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "id": "W-n80cCRCbjE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import Replicate\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "w6P5tBp4Cn5h"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdIrz3mmZKAC",
        "outputId": "ace1411e-0bf2-4807-ab29-187757fb6579"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.11.17)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m987.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/pNcQ5XXMgH4?si=JoIOVjlaNlRtUuzU\", add_video_info=True)"
      ],
      "metadata": {
        "id": "nl4Pg1qGYlxj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = loader.load()"
      ],
      "metadata": {
        "id": "VI888QccZCDh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7kz8WOIZZzm",
        "outputId": "eabf2bfc-14b7-48ae-d148-512dee4342d2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"what is going on good people again right now we have a super exciting tutorial because we are going to take YouTube transcripts and we're going to pass them to open Ai and the way that we're going to do that is via a library called Lang chain which is what this entire series is about now before we jumped into it I wanted to show a diagram again I think these diagrams are helpful but you have to let me know so just let me know in the comments here so I wanted to do an overview about what we're actually going to be writing out in code because I think it's a little easier to see in pictures first so the way this is going to work is we're going to have a video a YouTube video we're going to pass it we're going to pass it a URL and then what Lang chain is going to help us do is it's going to help us load this video as a document and a document just means you're going to be taking the transcript which is the text of the video and you're going to be loading it as a document which is something that lane chain can help understand now with that document we're then going to go generate a summary of it and the way that link chain is going to do this is it's going to create a prompt for us that says hey generate me a concise summary of the following text and then it's going insert the transcript of the YouTube video which is pretty sweet and this is going to happen in open Ai and this is going to happen to be an API call and then what we get out the other end is open AI is going to tell us hey this video is about XYZ now an interesting part about this and where it gets kind of confusing is well what happens if your video is too long oh no our video two is too long we can't pass this because say you're looking at a YouTube video and it's like an hour long well you can't pass all that transcript into open AI because they have a token limit and this is where a lot of the ergonomics of Lang chain really come to help out here now what we're going to do is we're actually going to split up that text so we're going to still see that it's from video two but we're going to have our document one document two document three and then what Lang chain is going to help us do is it's going to go to open Ai and it's going to say hey I want you to generate a summary for me of document one generate of document 2 generate of document three now the cool part about this is that this is all under the hood the cool part is then what it's going to do is it's going to say hey please generate me a summary of these summaries and then all of a sudden open AI is going to give us a summary of the summaries and the conclusion you get with the video is all the way about now this is one method of kind of combining documents like this and this is called the map reduce method but we'll get into that in a second when we talk about the different chain types all right that's enough diagrams let's look at some code here all right now that we're looking at some code here our first import statements uh this the star of the show here is going to be the YouTube loader this is going to be the tool that is going to help us do this we're going to uh import open Ai and we're going to import load summarize chain because this is going to be the chain that's going to help summarize for us so let's go ahead and run those I also had to install YouTube's transcripts API and then also pytube as well in case you uh run on that same problem so with the YouTube loader we're going to call Dot from YouTube URL and we are going to pass it a single YouTube url here and what that'll do is we're going to store that in a loader so to get it ready and kind of stage it and then we're actually going to call Dot load on it which is going to do the loading for us and I wanted to print this out and show you what we have here so if we have if we look at this result you can see that the result is a list of items it's very important we'll talk about this in a second year and then we just have some metadata on it but it is going to be a list of documents and these are the things that lane chain can help understand and can process for us and in this document you can see here that there's a page context which is going to be the transcript that is from this video and then we also have some interesting metadata too about the video itself but I'm going to go ahead and close this here we're going to uh instantially oh I want I need to load the open AI key we're going to initialize our large language model which is going to be the open AI one and then we're going to call load summarize chain we're going to pass it our model we're going to say chain type equals stuff important here we're going to talk about why this is changing later we're going to say verbose equals false because we don't want to see anything and then we're going to pass it the result that we loaded in which is the the document or the list of documents that we had let's go ahead and run this and then all of a sudden we get cool Pedro Pascal shared his experiences shooting HBO's Last of Us awesome so just based off the transcript it has a some summary of the YouTube video for us nice but what if you have a long video so I wanted to show you this one here we have another YouTube video which is going to be a podcast of my first million on here we hear some Sean talk and you can see that it is going to be almost 60 Minutes long and this is quite long and spoiler alert it's too long for open AI uh for the token limit that they have so let me show you this though we're going to load this in we're going to load the result you can see it takes a little bit and then we're going to say load summarize chain okay cool with chain type equals stuff and we're going to run this result here and then oh no we have an error it's trying to do something up here and it says this model's maximum context is uh 4097 tokens you've requested almost fifteen thousand and that's no good because that's too long so in the old days before Lang chain what we'd have to do here is we'd have to figure out some way to either run multiple pieces ourselves manually copy and paste it'd be a freaking mess we don't want to do any of that stuff so the problem is your transcript or your document is too long now what we're going to do here is we're actually going to split up that document which is what we saw earlier on the diagram and so I'm going to load in the recursive character splitter and I'm going to get this loaded here and I'm just going to set a chunk size of 2000. you can play with this it might be different for your use case whatever you want but if you're not getting what you need try switching this variable if you want some help there I'm going to load up that text footer and now what I'm going to do is I'm going to load in that single YouTube video into the text splitter and what it's going to do for me is actually I want to show you this here uh text and so let's let's first check out the type of text it is going to be a list okay cool let's see what it's a list of and you can see here it's a list of documents and this page context is still quite long but it's we're aiming for a chunk size of about 2 000. I just want to show you what a chunk size of 100 would look like and so we have a a list of documents again with a page context and this page context is only about a hundred characters long ish or 100 tokens long-ish it's it's uh it's interesting there and so if we were to look at no I don't want to do type I want to do length so if we're to do length of how many texts we have we have 522 and that's because it's taking our entire transcript and it's basically putting it into chunks roughly of a of a hundred if we're to do a thousand for chunks you can see here it's roughly 10 times less which is going to be on the 51. so this is a way to split up your documents and so now we have a whole bunch of documents um that are length of what we set right here but I'm going to set this back to 2000. nice and then what we're going to do is I'm going to call the llm here but I'm going to change the chain type and in fact before we did this I want to I want to show you the issue here um let's do chunk size 2000 and then we're going to do stuff and I'm going to call run and let's do oh I want to do this on text let's do run right here and so the issue is that we have again this is the maximum model length but we've requested all these documents together because when you do chain type equals stuff what you're doing is you're saying the Lang chain hey I want you to take all my documents and stuff them into the prompt that you're feeding open AI now there's a way around this not a way around this but an alternative is if you change the type to mapreduce that is when you're going to start to say hey just give me a summary of all these different documents that you have and then generate me a final summary so if we change it to mapreduce I'm going to go ahead and run this and let's give this a sec because this is going to make multiple API calls because what it's actually doing is it's making a uh it's telling hey open AI I want you to give me a summary of each one of these different documents and you saw how we had quite a uh a few number of documents cool well nice so we just had this long transcript and what we just had is now we have the summary of what this transcript says but I wanted to show you what it this actually looks like underneath the covers of what um Lang chain is doing and so what I'm going to do here is I'm going to set for both equals true which gives you insight as to the calls that laying chain is making the open AI this is going to get kind of confusing so I just want to do the first four documents on here which is you know the first little bit of the video that we loaded and so what we're going to look at here is we're going to look at all right we're doing a mapreduce document chain cool and so the very first call that it's saying to open AI is write me a concise summary of The Following nice so here is the following statement and this is one of the document chunks that we submitted beforehand and then it's saying hey again I want you to write me a concise summary of the following now here's the second document that we wanted it to summarize and then here's the third document and then here's the fourth document now the cool part is what you can see that gets returned is we have four different summaries of four different documents so summary One summary two summary three and summary four and the reason why is because we just wanted to see the first four that we had up here so we have all those summaries and then what it said was is basically write me a concise summary of the following so a summary of the summaries and then what we get is we get this uh summary of the summaries that's right here nice um it's cool now what if you have multiple videos that you want to do well in this case I have a YouTube url list I'm just passing it two different videos I'm going to get a list ready that is going to hold my text for me I'm going to get my uh character splitter ready and I'm going to say hey for URL in this list of URLs I want you to load up the video or get the loader ready I want you to load the video and then I want you to extend this list with the documents that you've split it into so in this case I have two YouTube videos I'm just going to go through both of them right there and then I'm going to call the summarize scan again with mapreduce in this case I don't really want to do verbose equals true because you already saw what that looked like but now what it's doing is it's going through both those videos it's split it splitting them up into separate documents in case that they're in case they're too long and then it's generating a summary for me now these were two videos about two completely different things and so this it starts off with a golf video about how to build a golf course in your backyard so it says cool blah blah looks great and then now it goes into the second summary which is around uh a uh interview between Bella Ramsay and Pedro Pascal about what they were doing so that is how you do uh loading up YouTube videos with a transcript and with the summaries I hope that that was helpful for you please let me know if the diagram was helpful I'm happy to do more videos and as always please leave please leave comments about how we can improve the videos and about your own personal uh business problems that we can help solve I'll see you later\", metadata={'source': 'pNcQ5XXMgH4', 'title': 'LangChain 101: YouTube Transcripts + OpenAI', 'description': 'Unknown', 'view_count': 20789, 'thumbnail_url': 'https://i.ytimg.com/vi/pNcQ5XXMgH4/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCmP9TXvB4nm22ZX7b5Tl0AagEU3A', 'publish_date': '2023-02-23 00:00:00', 'length': 668, 'author': 'Greg Kamradt (Data Indy)'})]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Falcon model\n",
        "#llm = Replicate(model=\"joehoover/falcon-40b-instruct:7eb0f4b1ff770ab4f68c3a309dd4984469749b7323a3d47fd2d5e09d58836d3c\")\n",
        "# text = \"\"\"Lorem ipsum is derived from the Latin phrase \"dolorem ipsum\", which roughly translates to \"pain itself\". It's been the industry standard dummy text since the 1500s, when an unknown printer scrambled a galley of type to make a type specimen book.\n",
        "# Lorem ipsum helps designers plan out where content will sit without needing to wait for the content to be written and approved. It features scrambled Latin text, which emphasizes the design over content of the layout.\n",
        "# You can use a Lorem ipsum generator to create Lorem ipsum text. You can also add Lorem ipsum to a Microsoft Word document by putting in a number representing how many paragraphs you would like, and then how many sentences per paragraph.\"\"\"\n",
        "# prompt = f\"explain this content in detail (within 500 words): {text}\"\n",
        "# llm(prompt)"
      ],
      "metadata": {
        "id": "hqT_IflkCsMO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mistral model\n",
        "llm = Replicate(model=\"mistralai/mistral-7b-instruct-v0.1:5fe0a3d7ac2852264a25279d1dfb798acbc4d49711d126646594e212cb821749\")"
      ],
      "metadata": {
        "id": "ZwbyCLtbcRC9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=False)\n",
        "chain.run(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "yTMuiLF9Wo05",
        "outputId": "5d8a8b8d-93d1-4a26-ac95-6d745f07d522"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThis tutorial will cover how to use Lang Chain to load YouTube videos and generate summaries of them using the Open AI API. The tutorial will explain how to split long videos into smaller chunks, how to use the recursive character splitter to split the video, and how to use the map reduce method to combine the summaries of the different chunks into a final summary. The tutorial will also cover how to use the YouTube loader to load the video, and how to use the load summarize chain to generate the summaries. The tutorial will provide code examples to help developers understand the process.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnEAG2IeZz84"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}